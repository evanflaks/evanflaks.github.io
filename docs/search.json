[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am Evan Flaks and this is my Machine Learning blog."
  },
  {
    "objectID": "posts/kernel/index.html",
    "href": "posts/kernel/index.html",
    "title": "Sparse Kernelized Logistic Regression",
    "section": "",
    "text": "Implementation"
  },
  {
    "objectID": "posts/perceptron/index.html",
    "href": "posts/perceptron/index.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "Abstract\nIn this project, I implement the perceptron algorithm from scratch using PyTorch to explore how linear classifiers work in both two-dimensional and higher-dimensional spaces. The perceptron is one of the earliest and most foundational machine learning algorithms, and this blog post walks through its logic, gradient updates, and training behavior. I apply the perceptron to synthetic datasets to examine its performance on linearly separable versus non-linearly separable data, and I visualize how the decision boundary and loss evolve over time. The goal is to gain an intuitive and practical understanding of how the perceptron learns from data and where its limitations lie.\n\n\nMy Perceptron Implementation\nThis project uses the perceptron.py script. The LinearModel class defines the basic structure, including methods to initialize the weight vector w, compute linear scores for input data (score), and make binary predictions (predict). The Perceptron class inherits from LinearModel and adds a loss method that calculates the misclassification rate. Finally, the PerceptronOptimizer class defines a step method that updates the model’s weights by applying the perceptron rule to a single data point.\nThe grad() function computes the update for the perceptron algorithm. The perceptron algorithm updates the weights only when a data point is misclassified. A point is misclassified when: \\[\\langle \\textbf{w},\\textbf{x}_i \\rangle \\cdot y_i &lt; 0\\] In the grad function, I convert the labels of \\(\\{0,1\\}\\) to \\(\\{-1,1\\}\\) by using \\[y' = 2y-1\\] Then, it computes the score \\(s = \\langle \\textbf{w},\\textbf{x}_i \\rangle\\), and if \\(s \\cdot y' &lt; 0\\), the point is misclassified. In that case, we return the update \\[-y' \\cdot \\textbf{x}_i\\] This pushes the weights in a direction that would correctly classify the point. If the point is already classified correctly, no update is needed, and the function returns a zero vector.\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer, LinearModel\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\nThe code above re-reads the contents of the perceptron.py file, so that changes made in that file will be reflected in this notebook.\n\n\nCreating and Visualizing Sample Data Points\nThe code below generates and visualizes synthetic 2D data for training a perceptron model. It uses PyTorch to create n_points (default 300) split into two classes, with half labeled as 0 and the other half as 1. Each data point is generated by adding Gaussian noise to the class label, creating two slightly overlapping clusters in a 2D space. An additional bias term (column of ones) is added to the feature matrix X. The plot_perceptron_data function then visualizes the data using Matplotlib, plotting class 0 and class 1 points with different markers and slight color variations.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    \n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = 2*y[ix]-1, facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\n\n\nTesting My Perceptron Algorithm\nNow that we have implemented our perceptron algorithm and have some simple data to work with, it’s time to check our implementation by running this “minimal training loop” below. This code initializes a perceptron and its optimizer, then enters a loop where it continually calculates the loss over the entire dataset and records this loss. In each iteration, a random data point is selected and used to update the perceptron’s weights. The loop continues until the loss reaches zero, implying that the data is linearly separable and the model has perfectly classified the training examples.\n\nfrom perceptron import Perceptron, PerceptronOptimizer\nimport torch\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n\nWe can track the progress of our training by checking the values of the loss function over time. The code below visualizes the evolution of the loss during perceptron training. It first plots a line graph of the loss values stored in loss_vec using a slategrey color. Then, it overlays a scatter plot to mark each individual loss measurement at each iteration (with the x-values generated by torch.arange(len(loss_vec))). Finally, it sets the x-axis label to “Perceptron Iteration (Updates Only)” and the y-axis label to “loss,” clearly labeling the plot to show how the loss changes with each update step.\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\nAs we can see, over the course of the iterations, the loss value (y-axis) goes to 0, which indicates perfect training accuracy. The perceptron experiences some initial fluctuations in the loss (with a few notable spikes), but eventually drives the loss to zero and keeps it there for the remainder of the updates. This indicates that the dataset is linearly separable, and the perceptron successfully found a separation that classifies all training examples correctly. The spikes represent moments when a particular data point was misclassified and the weights were adjusted, but after enough updates, the model converges to perfect classification.\n\n\nExperiments\n\nEvolution of Loss Function During Training: Linearly Separable Data\nUsing 2D data that is linearly separable, the perceptron algorithm converges to weight vector \\(\\vec{w}\\), describing a separating line.\nThe code below repeatedly performs perceptron updates on randomly selected misclassified points from the dataset until the model achieves zero classification error. For each update, it plots the old decision boundary (before the weight update) as a dashed line and the new decision boundary (after the update) as a solid line on a subplot. The misclassified point used for the update is also highlighted. These plots are arranged in a 2x3 grid, showing the evolution of the model’s decision boundary over successive updates. This gives a clear visual demonstration of how the perceptron learns to separate the data through linear updates. Citation: this code was provided from these lecture notes.\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\ntorch.manual_seed(1234567)\n\n# initialize a perceptron \np = Perceptron()\nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams[\"figure.figsize\"] = (7, 5)\nfig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\nmarkers = [\"o\", \",\"]\nmarker_map = {-1 : 0, 1 : 1}\n\n# initialize for main loop\ncurrent_ax = 0\nloss = 1\nloss_vec = []\n\nwhile loss &gt; 0:\n    ax = axarr.ravel()[current_ax]\n\n    # save the old value of w for plotting later\n    old_w = torch.clone(p.w)\n\n    # make an optimization step -- this is where the update actually happens\n    # now p.w is the new value \n\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    local_loss = p.loss(x_i, y_i).item()\n\n    if local_loss &gt; 0:\n        opt.step(x_i, y_i)\n    # if a change was made, plot the old and new decision boundaries\n    # also add the new loss to loss_vec for plotting below\n    if local_loss &gt; 0:\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[2*(y[i].item())-1]])\n        # draw_line(w, -10, 10, ax, color = \"black\")\n        ax.set_title(f\"loss = {loss:.3f}\")\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n        current_ax += 1\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nNon-Linearly Separable Data\nNow for 2D data that is not linearly separable, the perceptron algorithm will not settle on a final value of \\(\\vec{w}\\), but will instead run until the maximum number of iterations is reached, without achieving perfect accuracy.\nThe code below trains a perceptron on 2D data that is not linearly separable by adding significant noise to the dataset. It runs the training loop for a fixed number of iterations (1000), since the perceptron can’t perfectly separate the classes in this case. At each step, it selects a random data point and updates the model weights if the point is misclassified. After training, it generates two plots: one showing the data and the final decision boundary, and another showing how the perceptron’s misclassification rate (loss) evolved over time.\n\nimport torch\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# Helper: draw decision boundary line from weight vector\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    ax.plot(x, y, **kwargs)\n\n# Generate NON-linearly separable data\nX, y = perceptron_data(n_points=300, noise=0.8)  # Increase noise for overlap\nn = X.size(0)\n\n# Initialize model + optimizer\ntorch.manual_seed(42)\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\n# Training loop with max iterations\nmax_iters = 1000\nloss_vec = []\n\nfor iteration in range(max_iters):\n    loss = p.loss(X, y).item()\n    loss_vec.append(loss)\n\n    # pick random point\n    i = torch.randint(n, size=(1,))\n    x_i = X[i[0]]  # shape: (p,)\n    y_i = y[i[0]]  # scalar\n\n    opt.step(x_i, y_i)\n\n# --- Visualization ---\n\n# 1. Plot the data with the final decision boundary\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\n\n# Left: Data + final line\nplot_perceptron_data(X, y, ax[0])\ndraw_line(p.w, x_min=-1, x_max=2, ax=ax[0], color='black')\nax[0].set_title(\"Data with Final Decision Boundary\")\n\n# Right: Loss over time\nax[1].plot(loss_vec, color='darkred')\nax[1].set_title(\"Loss over Training\")\nax[1].set_xlabel(\"Iteration\")\nax[1].set_ylabel(\"Misclassification Rate\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMore Than Two Features\nThe perceptron algorithm is also able to work in more than 2 dimensions.\n\nimport torch\nimport matplotlib.pyplot as plt\n\n# Generate higher-dimensional data (5D + bias)\ndef perceptron_data_highdim(n_points=300, noise=0.2, p_dims=5):\n    y = torch.arange(n_points) &gt;= int(n_points / 2)\n    X = y[:, None] + torch.normal(0.0, noise, size=(n_points, p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), dim=1)  # Add bias column\n    return X, y\n\n# Generate data\nX, y = perceptron_data_highdim(p_dims=5)\nn = X.size(0)\n\n# Initialize model and optimizer\ntorch.manual_seed(42)\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\n# Train the model\nmax_iters = 1000\nloss_vec = []\n\nfor _ in range(max_iters):\n    loss = p.loss(X, y).item()\n    loss_vec.append(loss)\n    \n    i = torch.randint(n, size=(1,))\n    x_i = X[i[0]]\n    y_i = y[i[0]]\n    \n    opt.step(x_i, y_i)\n\n# Plot loss over time\nplt.figure(figsize=(6, 4))\nplt.plot(loss_vec, color='navy')\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Misclassification Rate\")\nplt.title(\"Loss During Training (5D Data)\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see from the graph above, the loss consistently drops and eventually reaches zero and stays there. This suggests that the data is linearly separable in the 5D space, because we can eventually reach a loss of 0 which is perfect accuracy.\n\n\nRuntimes\n\nQ: What is the runtime complexity of a single iteration of the perceptron algorithm? Does the runtime complexity of a single iteration depend on the number of data points \\(n\\)? What about the number of features \\(p\\)? If you implemented minibatch perceptron, what is the runtime complexity of a single iteration of the minibatch perceptron algorithm?\n\nA single iteration of of the perceptron algorithm involves the following steps:\n\nSelect one data point \\((x_i,y_i)\\), which takes constant time \\(O(1)\\).\nCompute the score \\(s = \\langle \\textbf{w},\\textbf{x}_i \\rangle\\). This is a dot product of two length-\\(p\\) vectors, so the run-time is \\(O(p)\\).\nCheck if misclassified and, if so, compute and apply the update. Computing the update is \\(-y_i \\cdot x_i\\), which again has runtime \\(O(p)\\). Updating the weights vector is vector addition and therefore has runtime \\(O(p)\\).\n\nThus, the total complexity per iteration is \\(O(p)\\).\nThis runtime does not depend on \\(n\\) because only one data point is processed. However, both the dot product and weight vector update involve vectors of length \\(p\\), so the runtime does depend on \\(p\\).\nIn minibatch perceptron, a batch of \\(b\\) data points is processed together. So, for every \\(b\\), the program do the same process outlined above that had a runtime of \\(O(p)\\).\nSo the total runtime per iteration of minibatch perceptron is \\(O(b \\cdot p)\\)\n\n\nConclusion\nThrough hands-on experimentation with the perceptron algorithm, I observed how effectively it learns a linear decision boundary when the data is linearly separable, converging to zero classification error over time. However, in cases where the data is not linearly separable, the perceptron fails to converge and continues to update the weights without settling, highlighting its limitations in more complex real-world scenarios. Extending the perceptron to higher dimensions confirmed that the algorithm can scale beyond 2D, with the loss curve providing insight into whether linear separation is likely. Overall, this project deepened my understanding of how simple learning algorithms operate and set the stage for exploring more advanced models like logistic regression or support vector machines."
  },
  {
    "objectID": "posts/loans/credit-risk.html",
    "href": "posts/loans/credit-risk.html",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "Abstract\nIn this project, I developed a machine learning-based loan approval system designed to predict the likelihood of loan default and optimize lending decisions for a financial institution. Using a dataset containing borrower information such as age, income, employment length, homeownership status, and credit history, I first created data visualizations and summary tables to explore trends in the data. Then, I implemented a logistic regression model to classify applicants as either high-risk (default) or low-risk (non-default) and create a score function with a weight vector to weight each feature into the decision process. Then, to decide on a threshold value for my score function, I conducted a profit optimization analysis, adjusting approval thresholds to maximize expected returns. Through this study, I evaluated how loan approval rates varied across age groups, income levels, and loan purposes, ultimately assessing the fairness and efficiency of an automated credit decision system.\n\n\nData Extraction\nWe begin by downloading the data from the source. The columns in this data include extensive information about the prospective borrower – age, income, home owndership, loan intent, etc.\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\n\nData Exploration\nNow I will create some visualizations to explore patterns in the data.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='loan_intent', y='person_age', hue='person_home_ownership', data=df_train)\nplt.title(\"Age Distribution by Loan Intent and Homeownership Status\")\nplt.xlabel(\"Loan Intent\")\nplt.ylabel(\"Age\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Homeownership\")\n\n\n\n\n\n\n\n\nThis boxplot helps visualize the distribution of borrowers’ ages across different loan intents, while also distinguishing between different homeownership statuses. An immediate observation that I have is that the interquartile range for every loan type and homeownership status falls around 20-30 years of age, meaning that is the main age group seeking all types of loans. Another notable observation is the outliers per category. There are a lot more y-axis outliers (i.e. older people) that rent their homes, meaning it is common for older renters to be seeking a loan in almost all loan categories as opposed to older homeowners or mortgagers. Further, the largest age outlier category falls in the blue medical section of the x-axis, meaning that older-age renters are often seeking medical loans.\n\nplt.figure(figsize=(12, 6))\nsns.scatterplot(x='person_income', y='loan_int_rate', hue='loan_status', data=df_train, alpha=0.7)\nplt.xscale(\"log\")  # Log scale to handle wide income range\nplt.title(\"Interest Rate vs. Income by Loan Status\")\nplt.xlabel(\"Annual Income (Log Scale)\")\nplt.ylabel(\"Interest Rate (%)\")\nplt.legend(title=\"Loan Defaulted\")\nplt.show()\n\n\n\n\n\n\n\n\nThis scatter plot helps us visualize the relationship between a person’s income and the interest rate they are offered, and whether or not that loan was defaulted. As we can see by the scattering, there is no clear relationship between income and interest rate; there are both high income people with low and high interest rates, and there are low income people with both high and low interest rates. However, the abundance of orange to the top and left of the plot tells us that those with lower annual incomes tend to default on their loans much more often as opposed to higher-income individuals.\n\nsummary_table = df_train.groupby('person_emp_length').agg({\n    'loan_amnt': 'mean',\n    'loan_int_rate': 'mean',\n    'loan_percent_income': 'mean'\n}).reset_index()\n\n# Rename columns for clarity\nsummary_table.columns = ['Employment Length (Years)', 'Avg Loan Amount', 'Avg Interest Rate (%)', 'Avg Loan as % of Income']\n\n# Display the summary table\ndisplay(summary_table)\n\n\n\n\n\n\n\n\nEmployment Length (Years)\nAvg Loan Amount\nAvg Interest Rate (%)\nAvg Loan as % of Income\n\n\n\n\n0\n0.0\n8572.957492\n11.212005\n0.174275\n\n\n1\n1.0\n9196.537307\n11.356443\n0.178396\n\n\n2\n2.0\n9142.199217\n11.302131\n0.174799\n\n\n3\n3.0\n9448.739572\n11.095799\n0.170120\n\n\n4\n4.0\n9392.330416\n11.215608\n0.169326\n\n\n5\n5.0\n9596.843434\n10.857377\n0.171835\n\n\n6\n6.0\n9735.197368\n10.775047\n0.172580\n\n\n7\n7.0\n10095.776060\n10.930345\n0.163076\n\n\n8\n8.0\n10439.578714\n10.577886\n0.162084\n\n\n9\n9.0\n10799.319419\n10.904209\n0.160971\n\n\n10\n10.0\n10989.527629\n10.994492\n0.163850\n\n\n11\n11.0\n10832.043478\n10.936378\n0.146348\n\n\n12\n12.0\n10988.591703\n10.562252\n0.155087\n\n\n13\n13.0\n10824.500000\n10.692848\n0.161286\n\n\n14\n14.0\n11635.018727\n10.776500\n0.155393\n\n\n15\n15.0\n10270.750000\n10.474341\n0.156400\n\n\n16\n16.0\n11522.674419\n9.895086\n0.157364\n\n\n17\n17.0\n9693.181818\n10.468352\n0.140101\n\n\n18\n18.0\n10328.481013\n10.228333\n0.136329\n\n\n19\n19.0\n13135.795455\n11.061190\n0.153864\n\n\n20\n20.0\n12926.973684\n11.654412\n0.175526\n\n\n21\n21.0\n10059.166667\n12.068889\n0.144333\n\n\n22\n22.0\n10470.000000\n12.206429\n0.144000\n\n\n23\n23.0\n9700.000000\n11.513333\n0.188333\n\n\n24\n24.0\n10045.000000\n9.986250\n0.140000\n\n\n25\n25.0\n7625.000000\n10.353333\n0.111667\n\n\n26\n26.0\n12000.000000\n8.540000\n0.130000\n\n\n27\n27.0\n13200.000000\n9.938000\n0.186000\n\n\n28\n28.0\n17666.666667\n15.330000\n0.220000\n\n\n29\n29.0\n25000.000000\n13.430000\n0.340000\n\n\n30\n30.0\n24000.000000\n10.380000\n0.155000\n\n\n31\n31.0\n13500.000000\n10.450000\n0.075000\n\n\n32\n34.0\n7500.000000\n13.550000\n0.150000\n\n\n33\n38.0\n20000.000000\n9.880000\n0.190000\n\n\n34\n41.0\n3000.000000\n7.510000\n0.060000\n\n\n35\n123.0\n27500.000000\n11.280000\n0.345000\n\n\n\n\n\n\n\nFrom this summary table, we can see that typically those who have been employed longer get access to larger lines of credit. While the correlation is not super strong, it can be said that those who have been employed a short time (0-6) years are much more likely to get a loan that is worth less than $10,000.\n\n\nBuilding a Model to Find a Weight Vector\nBelow, I have trained a logistic regression model to predict whether a borrower will default on a loan based on all of the given features in the data set aside from loan grade and loan status (the target variable). I first separate the features into numeric (e.g., income, loan amount) and categorical (e.g., homeownership, loan intent). The numeric features are standardized using StandardScaler, while categorical features are one-hot encoded using OneHotEncoder, all managed through a ColumnTransformer. A Pipeline is then created to preprocess the data and train a logistic regression model. Finally, the weight vector (model coefficients) is retrieved, and cross-validation is performed to assess the model’s accuracy across five folds. The accuracy scores and mean accuracy are printed to evaluate the model’s predictive performance.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\n\n\n\n# List of features (excluding forbidden ones)\nfeatures = [\n    \"person_age\", \"person_income\", \"person_home_ownership\", \"person_emp_length\",\n    \"loan_intent\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\",\n    \"cb_person_default_on_file\", \"cb_person_cred_hist_length\"\n]\n\n# Target variable\ntarget = \"loan_status\"\n\n# Example placeholder for DataFrame\n\n# Splitting numeric and categorical features\nnumeric_features = [\"person_age\", \"person_income\", \"person_emp_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\"]\ncategorical_features = [\"person_home_ownership\", \"loan_intent\", \"cb_person_default_on_file\"]\n\n# Preprocessing\nnumeric_transformer = StandardScaler()\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ]\n)\ndf = df_train.dropna()\n# Define logistic regression model\nmodel = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n])\n\n# Prepare data\nX = df[features]\ny = df[target]\n\n# Ensure target variable is binary (1 = Default, 0 = Non-Default)\ny = y.map({'Default': 1, 'Non-Default': 0}) if y.dtype == 'object' else y\n\n# Fit the model\nmodel.fit(X, y)\n\n# Retrieve the weight vector\nweights = model.named_steps['classifier'].coef_\nprint(\"Weight vector (w):\", weights)\n\n# Cross-validation to evaluate model accuracy\ncv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\nprint(\"Cross-validation accuracy scores:\", cv_scores)\nprint(\"Mean accuracy:\", np.mean(cv_scores))\n\nWeight vector (w): [[-0.0383707   0.04510115 -0.02445074 -0.58076891  1.03715014  1.3244998\n  -0.01195797  0.12828473  0.37763254 -1.36247275  0.86221669  0.42979327\n  -0.37518745  0.50616243  0.24713985 -0.19722704 -0.60501984 -0.0351749\n   0.04083611]]\nCross-validation accuracy scores: [0.85268442 0.85421213 0.84566688 0.84654006 0.84981445]\nMean accuracy: 0.8497835888866307\n\n\nFrom this we can see that our weight vector for all of the features is w = [-0.0383707 0.04510115 -0.02445074 -0.58076891 1.03715014 1.3244998 -0.01195797 0.12828473 0.37763254 -1.36247275 0.86221669 0.42979327 -0.37518745 0.50616243 0.24713985 -0.19722704 -0.60501984 -0.0351749 0.04083611]\nAnd our mean accuracy across our cross-validations is 0.849, meaning we predicted around 85% of loan approval decisions to be correct (did not default).\n\n\nFinding a Threshold\nNow we must find a threshold. To do this, the code below first generates predicted probabilities of loan default from the logistic regression model and defines a range of threshold values between 0 and 1. The profit if a loan is repaid and the loss if a loan defaults are computed using the following assumptions:\n\nIf ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍repaid ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍in ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍full, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍profit ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍bank ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍equal ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan_amnt(1 + 0.25loan_int_rate)**10 - loan_amnt. ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍This ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍formula ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍assumes ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍profit ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍earned ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍by ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍bank ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍on ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍a ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍10-year ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍equal ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍25% ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍of ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍interest ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍rate ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍each ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍year, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍with ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍other ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍75% ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍of ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍interest ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍going ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍things ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍like ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍salaries ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍people ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍who ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍manage ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍bank. ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍It ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍extremely ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍simplistic ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍and ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍does ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍not ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍account ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍inflation, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍amortization ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍over ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍time, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍opportunity ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍costs, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍etc.\nIf ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍borrower ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍defaults ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍on ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍“profit” ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍bank ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍equal ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan_amnt(1 + 0.25loan_int_rate)**3 - 1.7*loan_amnt. ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍This ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍formula ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍corresponds ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍same ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍profit-earning ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍mechanism ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍as ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍above, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍but ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍assumes ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍borrower ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍defaults ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍three ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍years ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍into ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loan ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍and ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍bank ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loses ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍70% ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍of ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍principal.\n\nFor each threshold, the model classifies loan applicants, determining whether they are approved or denied. The total expected profit is then computed by summing profits from repaid loans and losses from defaulted loans. The optimal threshold is selected as the one that yields the highest total profit.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate predicted probabilities from the logistic regression model\ny_prob = model.predict_proba(X)[:, 1]\n\n# Define a range of threshold values to test\nthresholds = np.linspace(0, 1, 100)\n\n# Extract loan amounts and interest rates as numpy arrays\nloan_amounts = X[\"loan_amnt\"].to_numpy()\ninterest_rates = X[\"loan_int_rate\"].to_numpy()\n\n# Ensure interest rates are correctly scaled (divided by 100 if necessary)\nif interest_rates.max() &gt; 1:  # If the max value is greater than 1, assume percentages need scaling\n    interest_rates /= 100\n\n# Compute profit if loan is repaid and loss if defaulted (vectorized)\nprofit_if_repaid = loan_amounts * ((1 + 0.25 * interest_rates) ** 10) - loan_amounts\nloss_if_defaulted = loan_amounts * ((1 + 0.25 * interest_rates) ** 3) - (1.7 * loan_amounts)\n\n# Ensure y is a NumPy array\ny_np = y.to_numpy()\n\n# Vectorized computation of profit for each threshold\nprofits = np.zeros_like(thresholds)\n\nfor i, t in enumerate(thresholds):\n    predictions = (y_prob &gt;= t).astype(int)  # Convert probabilities to binary predictions\n    approved_loans = predictions == 0  # Loans that are approved\n\n    # Compute total profit\n    total_profit = np.sum(profit_if_repaid[(y_np == 0) & approved_loans]) + np.sum(loss_if_defaulted[(y_np == 1) & approved_loans])\n    profits[i] = total_profit\n\n# Find the threshold that maximizes profit\noptimal_threshold = thresholds[np.argmax(profits)]\nmax_profit = profits.max()\nexpected_profit_per_borrower = max_profit / len(y_prob)\n\n# Plot the profit curve\nplt.figure(figsize=(10, 6))\nplt.plot(thresholds, profits, label=\"Total Profit\", color='blue')\nplt.axvline(optimal_threshold, color='red', linestyle=\"--\", label=f\"Optimal Threshold: {optimal_threshold:.4f}\")\nplt.xlabel(\"Decision Threshold\")\nplt.ylabel(\"Total Profit\")\nplt.title(\"Profit Optimization for Loan Approval\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Output the results\nprint(f\"Optimal Threshold: {optimal_threshold:.4f}\")\nprint(f\"Maximum Profit: {max_profit:.2f}\")\nprint(f\"Expected Profit per Borrower: {expected_profit_per_borrower:.2f}\")\n\n\n\n\n\n\n\n\nOptimal Threshold: 0.4040\nMaximum Profit: 32086998.37\nExpected Profit per Borrower: 1400.75\n\n\nAbove, I have plotted a profit curve to visualize how profit changes with different decision thresholds, with the optimal threshold marked in red. As we can see, the threshold that optimizes profits is t = 0.4040, generating $1400.75 in profit per borrower.\n\n\nModel Evaluation: Bank’s Perspective\nNow that I have finalized our weight vector w and threshold t, I am going to evaluate the performance of the logistic regression model on the test dataset. The code below loads and cleans the test data by dropping missing values, extracts relevant features, and the target variable (loan_status) is mapped to binary values.\nUnder the financial formula assumptions provided above, the optimal threshold of t = 0.4040 is applied to classify loans as approved (0) or denied (1). The total profit is computed by summing profits from repaid loans and losses from defaulted loans within the approved subset. Finally, the expected profit per borrower is derived by dividing total profit by the number of test borrowers.\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test_dirty = pd.read_csv(url)\ndf_test = df_test_dirty.dropna()\n\nimport pandas as pd\nimport numpy as np\n\n# Extract relevant features from the test set (excluding forbidden ones)\nX_test = df_test[[\"person_age\", \"person_income\", \"person_home_ownership\", \"person_emp_length\",\n                  \"loan_intent\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\",\n                  \"cb_person_default_on_file\", \"cb_person_cred_hist_length\"]]\n\n# Extract true labels\ny_test = df_test[\"loan_status\"]\n\n# Ensure target variable is binary (1 = Default, 0 = Non-Default)\ny_test = y_test.map({'Default': 1, 'Non-Default': 0}) if y_test.dtype == 'object' else y_test\n\n# Get predicted probabilities for the positive class (default) using trained model\ny_prob_test = model.predict_proba(X_test)[:, 1]\n\n# Extract loan amounts and interest rates as numpy arrays\nloan_amounts_test = X_test[\"loan_amnt\"].to_numpy()\ninterest_rates_test = X_test[\"loan_int_rate\"].to_numpy()\n\n# Ensure interest rates are correctly scaled (divided by 100 if necessary)\nif interest_rates_test.max() &gt; 1:  # If the max value is greater than 1, assume percentages need scaling\n    interest_rates_test /= 100\n\n# Compute profit if loan is repaid and loss if defaulted (vectorized)\nprofit_if_repaid_test = loan_amounts_test * ((1 + 0.25 * interest_rates_test) ** 10) - loan_amounts_test\nloss_if_defaulted_test = loan_amounts_test * ((1 + 0.25 * interest_rates_test) ** 3) - (1.7 * loan_amounts_test)\n\n# Ensure y_test is a NumPy array\ny_test_np = y_test.to_numpy()\n\n# Apply the chosen threshold to make loan approval decisions\npredictions_test = (y_prob_test &gt;= optimal_threshold).astype(int)\napproved_loans_test = predictions_test == 0  # Loans that are approved\n\n# Compute total profit on the test set\ntotal_profit_test = np.sum(profit_if_repaid_test[(y_test_np == 0) & approved_loans_test]) + \\\n                    np.sum(loss_if_defaulted_test[(y_test_np == 1) & approved_loans_test])\n\n# Compute expected profit per borrower\nexpected_profit_per_borrower_test = total_profit_test / len(y_test_np)\n\nprint(f\"Total Profit on Test Set: {total_profit_test:.2f}\")\nprint(f\"Expected Profit per Borrower on Test Set: {expected_profit_per_borrower_test:.2f}\")\n\nTotal Profit on Test Set: 7684515.98\nExpected Profit per Borrower on Test Set: 1340.87\n\n\nAs we can see, the expected profit per borrower on the test set is $1340.87, which is very similar to the value of $1400.75 that was calculated on the training set. From a Bank’s perspective, our model is reasonably profitable and accurate.\n\n\nModel Evaluation: Borrower’s Perspective\nNow we will evaluate our model from the borrower’s perspective. This code analyzes the loan approval rates under the model’s decision system across different demographic and financial groups. The analysis is divided into three key perspectives:\nAge Groups: Borrowers are categorized into age brackets, and approval rates are computed for each group.\nLoan Type (Medical vs. Other): Loans are grouped into Medical and Other categories, and their respective approval and default rates are calculated.\nIncome Levels: Borrowers are divided into five quintile income brackets, and approval rates for each group are determined.\n\nimport pandas as pd\nimport numpy as np\n\n# Create a copy to avoid modifying the original DataFrame\ndf_test = df_test.copy()\n\n# Assign approval results safely\ndf_test.loc[:, \"approved\"] = approved_loans_test\n\n# Analyze approval rates across age groups\nage_groups = pd.cut(df_test[\"person_age\"], bins=[18, 25, 35, 50, 65, 100], labels=[\"18-24\", \"25-34\", \"35-49\", \"50-64\", \"65+\"])\napproval_rate_by_age = df_test.groupby(age_groups)[\"approved\"].mean()\n\n# Create a new column to categorize loans as 'Medical' or 'Other'\ndf_test.loc[:, \"loan_category\"] = df_test[\"loan_intent\"].apply(lambda x: \"Medical\" if x == \"MEDICAL\" else \"Other\")\n\n# Compute approval rates\napproval_rate_medical = df_test[df_test[\"loan_category\"] == \"Medical\"][\"approved\"].mean()\napproval_rate_other = df_test[df_test[\"loan_category\"] == \"Other\"][\"approved\"].mean()\n\n# Compute default rates\ndefault_rate_medical = df_test[df_test[\"loan_category\"] == \"Medical\"][\"loan_status\"].mean()\ndefault_rate_other = df_test[df_test[\"loan_category\"] == \"Other\"][\"loan_status\"].mean()\n\n# Analyze impact of income on loan approvals\nincome_groups = pd.qcut(df_test[\"person_income\"], q=5, labels=[\"Low\", \"Lower-Middle\", \"Middle\", \"Upper-Middle\", \"High\"])\napproval_rate_by_income = df_test.groupby(income_groups)[\"approved\"].mean()\n\n# Display results\nprint(\"Loan Approval Rates by Age Group:\")\nprint(approval_rate_by_age)\n\nprint(\"\\nLoan Approval and Default Rates by Loan Type:\")\nprint(f\"Medical - Approval Rate: {approval_rate_medical:.2f}, Default Rate: {default_rate_medical:.2f}\")\nprint(f\"Other - Approval Rate: {approval_rate_other:.2f}, Default Rate: {default_rate_other:.2f}\")\n\nprint(\"\\nLoan Approval Rates by Income Group:\")\nprint(approval_rate_by_income)\n\nLoan Approval Rates by Age Group:\nperson_age\n18-24    0.779661\n25-34    0.815186\n35-49    0.848432\n50-64    0.731707\n65+      1.000000\nName: approved, dtype: float64\n\nLoan Approval and Default Rates by Loan Type:\n\nLoan Approval and Default Rates for Medical vs. Other Loans:\nMedical - Approval Rate: 0.74, Default Rate: 0.28\nOther - Approval Rate: 0.82, Default Rate: 0.21\n\nLoan Approval Rates by Income Group:\nperson_income\nLow             0.575152\nLower-Middle    0.723222\nMiddle          0.835861\nUpper-Middle    0.901482\nHigh            0.973799\nName: approved, dtype: float64\n\n\nFrom the first table we can see that my model predicts that the group with the lowest loan approval rates is 50-64. Aside from that group, the younger age groups tend to have lower approval ratings. This means, according to my model, it is most difficult for people aged 50-64 to get loans. Whereas people above the age of 65 are guaranteed to be approved.\nFrom the second table we can see that my model predicts medical loans have a lower approval rating and a higher default rate when compared to other loans. So, according to my model, it is more difficult for people to get loans for medical expenses than it is for business, education, homes, etc., but it is also more common for people to default on medical loans.\nFrom the third table, we can see that my model predicts the loan approval rate to be worse for lower income individuals, and as someone moves into a higher income group, they have a higher chance of loan approval. Thus, it is much easer for a wealthier person to get access to credit under my system.\n\n\nReflection\nThoughout this project, I learned a lot about automated decision systems. While the model was designed to maximize lender profitability and reduce financial risk, these systems have far-reaching consequences beyond financial efficiency. Decisions made by models like mine directly impact people’s access to credit—a critical resource for economic mobility, education, healthcare, and entrepreneurship. By relying on historical data and statistical relationships, machine learning models can often reinforce existing inequalities in financial systems. For example, my study revealed that younger applicants and lower-income individuals had lower approval rates, reflecting biases where those already struggling financially find it even harder to secure credit. It is not feasible for banks to give out loans to people who are likely to default on them, and machine learning models can very accurately predict whether someone is high or low risk. However, these models are rarely 100% accurate (mine was 85%). For someone in a high-risk group that will be able to pay back a loan but never gets accepted, this decision-making system seems unfair and negatively impacts people from these high-risk groups.\nAnother controversy arises when discussing medical loans. Applicants seeking loans for medical expenses faced higher rejection rates due to their higher historical default rates. Considering ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍people ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍seeking ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍loans ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍medical ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍expense ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍have ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍high ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍rates ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍of ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍default, ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍it ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍fair ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍it ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍is ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍more ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍difficult ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍them ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍obtain ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍access ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍credit? In the context of credit, I would define a fair system as one that uses objective and relevant financial factors without discrimination on vulnerable groups. However, sick people are often vulnerable as they often cannot work and have no control over their financial situation. This highlights the flaws in purely data-driven credit decisions. While lenders must manage risk, rejecting medical borrowers based solely on historical default rates ignores the uncontrollable nature of medical crises. True fairness should account for context, distinguishing between defaults caused by financial irresponsibility and those driven by hardship. A more ethical system would incorporate alternative lending structures—such as flexible repayment plans or government-backed medical loans—to ensure vulnerable borrowers aren’t automatically excluded from financial support. The challenge is not just predicting risk, but balancing objective financial metrics with contextual and individual nuance in credit decisions."
  },
  {
    "objectID": "posts/logistic/index.html",
    "href": "posts/logistic/index.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "Abstract\n\nimport torch\nimport matplotlib.pyplot as plt\n\n%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\n\n\n\nPart A: Implementing Logistic Regression\nIn my logistic.py script, I have implemented a few classes to perform logistic regression on a data set.\nThe LinearModel class provides the foundation for linear models by maintaining a weight vector \\(w\\) and defining core functionality to compute scores and predictions. The score method calculates the raw output (dot product) for each data point in the feature matrix \\(X\\) by multiplying it with the model’s weight vector \\(w\\). If \\(w\\) has not been initialized yet, it randomly initializes it to a vector of the correct shape. The predict method then uses these scores to produce binary predictions by thresholding the score at zero; any value greater than zero becomes a 1.0 , otherwise 0.0.\nThe LogisticRegression class inherits from LinearModel and implements functionality specific to binary classification using the logistic loss. It introduces a loss method that calculates the average logistic loss over the dataset by applying the sigmoid function to the model’s scores to obtain probabilities, and then computing the cross-entropy loss with the true labels y. The grad method computes the gradient of this loss with respect to the weight vector \\(w\\), which is necessary for optimization. It does this by taking the derivative of the loss function, resulting in the formula \\[\\frac{1}{n} \\cdot X^{T} @ (\\sigma(a)-y)\\] Where \\(\\sigma(s)\\) is the vector of predicted probabilities. These methods enable learning the optimal weights for classification tasks through gradient-based updates.\nThe GradientDescentOptimizer class is responsible for updating the model’s weights using gradient descent with momentum. Initialized with a reference to a model (e.g., LogisticRegression), it keeps track of the previous weight vector to compute the momentum term. The step method performs a single optimization step using the formula \\[w_{k+1} = w_k - \\alpha \\cdot \\nabla L(w_k) + \\beta(w_k -w_{k-1})\\] Where \\(\\alpha\\) is the learning rate and \\(\\beta\\) is the momentum coefficient. If it’s the first step, the previous weight vector is simply initialized to the current weights. The momentum term helps smooth out updates and can accelerate convergence, especially in cases where the loss surface has narrow valleys or noisy gradients.\n\n\nPart B: Experiments\nBelow is I have written a few functions that will allow us to perform and vizualize various experiments.\nThe run_experiment function runs a logistic regression training loop using gradient descent with a specified learning rate (alpha) and momentum parameter (beta) for a set number of iterations. It initializes a LogisticRegression model and a GradientDescentOptimizer. During each iteration, the function computes the current loss and performs a gradient descent step using the specified parameters. The loss at each iteration is stored in a list, allowing for later analysis of convergence behavior. It returns both the loss history and the trained model.\nThe plot_decision_boundary function visualizes the decision boundary learned by a trained logistic regression model over a 2D feature space. It first defines a grid of (x, y) coordinates that spans the input data range and constructs a feature matrix that includes a bias term. It then uses the model to compute sigmoid probabilities over this grid and reshapes the results for contour plotting. The function plots a contour at the decision threshold (probability = 0.5), which represents the decision boundary. It overlays this boundary on a scatter plot of the original dataset, clearly showing how well the model separates the two classes.\nThe plot_loss_curve function plots the progression of logistic loss values recorded during the training process. It takes a list of loss values (one per iteration) and creates a line plot with iteration number on the x-axis and logistic loss on the y-axis. The resulting graph helps visualize whether the loss is decreasing consistently—a key indicator of successful convergence during training. A smooth, monotonically decreasing curve suggests that the gradient descent algorithm is working correctly.\n\ndef run_experiment(X, y, beta, alpha, iterations):\n    \"\"\"\n    Run gradient descent on the provided classification data for a given beta (momentum)\n    and learning rate alpha, returning the loss history and final model.\n    \"\"\"\n    model = LogisticRegression()\n    optimizer = GradientDescentOptimizer(model)\n    losses = []\n    for i in range(iterations):\n        loss = model.loss(X, y).item()\n        losses.append(loss)\n        optimizer.step(X, y, alpha=alpha, beta=beta)\n    return losses, model\n\n# === Visualization Functions ===\n\ndef plot_decision_boundary(model, X, y):\n    \"\"\"\n    Plot the decision boundary learned by the model along with the data.\n    We compute the sigmoid outputs on a grid and then plot a contour where\n    the decision boundary (σ(s)=0.5) lies.\n    \"\"\"\n    plt.figure(figsize=(8,6))\n    \n    # Determine grid boundaries\n    x_min, x_max = X[:,0].min() - 0.5, X[:,0].max() + 0.5\n    y_min, y_max = X[:,1].min() - 0.5, X[:,1].max() + 0.5\n    \n    # Create a meshgrid of points covering the input space\n    xx, yy = torch.meshgrid(torch.linspace(x_min, x_max, 100), \n                            torch.linspace(y_min, y_max, 100), indexing='xy')\n    # Note: bias term is 1 for all grid points\n    grid = torch.stack([xx.reshape(-1), yy.reshape(-1), torch.ones(xx.numel())], dim=1)\n    \n    # Compute probabilities on the grid\n    probs = torch.sigmoid(model.score(grid)).reshape(xx.shape)\n    \n    # Plot contour at probability 0.5 (decision boundary)\n    plt.contourf(xx, yy, probs.detach().numpy(), levels=[0, 0.5, 1], alpha=0.3, cmap='gray')\n    plt.contour(xx, yy, probs.detach().numpy(), levels=[0.5], colors='black')\n    \n    # Scatter plot of original data\n    plt.scatter(X[:,0][y==0], X[:,1][y==0], label=\"Class 0\", edgecolor='k')\n    plt.scatter(X[:,0][y==1], X[:,1][y==1], label=\"Class 1\", edgecolor='k')\n    plt.xlabel(\"Feature 1\")\n    plt.ylabel(\"Feature 2\")\n    plt.title(\"Decision Boundary after Training (Vanilla Gradient Descent)\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_loss_curve(losses):\n    \"\"\"\n    Plot the loss value as a function of iterations.\n    A monotonically decreasing curve is expected for a converging algorithm.\n    \"\"\"\n    plt.figure(figsize=(8,6))\n    plt.plot(losses, marker='o')\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Logistic Loss\")\n    plt.title(\"Loss over Gradient Descent Iterations (Vanilla Gradient Descent)\")\n    plt.grid(True)\n    plt.show()\n\n\nExperiment 1: Vanilla Gradient Descent (\\(\\beta=0\\))\nFirst let’s create some sample data to work with by running the following code\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\nNow we want to run a gradient descent for logistic regression with \\(\\alpha=0.1\\) and \\(\\beta=0\\), i.e no momentum. The code below runs my run_experiment function with those values and the above synthetic data, plotting the decision boundary for classification after training and the loss over the course of iterations.\n\niterations = 100\nalpha = 0.1\n\n# Vanilla GD (β = 0)\nlosses_vanilla, model_vanilla = run_experiment(X, y, beta=0.0, alpha=alpha, iterations=iterations)\nplot_decision_boundary(model_vanilla, X, y)\nplot_loss_curve(losses_vanilla)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs we can see from the first graph, the gradient ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍descent ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍for ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍logistic ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍regression ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍converges ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍to ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍a ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍weight ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍vector ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍\\(w\\) ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍that ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍looks ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍visually ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍correct, as it is mostly separating the blue data from the red data correctly.\nAs we can from the second graph, the loss decreases monotonically over the course of the iterations.\n\n\nExperiment 2: Gradient Descent with Momentum (\\(\\beta = 0.9\\))\nNow we want to use the same data set as we did in the first experiment, but this time we will implement momentum, setting \\(\\beta=0.9\\). The code below runs the experiemnt on the same data but with \\(\\beta=0.9\\) and \\(\\alpha=0.1\\) still.\n\niterations = 100\nalpha = 0.1\n\n# Gradient Descent with momentum (β = 0.9)\nlosses_momentum, model_momentum = run_experiment(X, y, beta=0.9, alpha=alpha, iterations=iterations)\n\n# Plotting the Loss Curves\nplt.figure(figsize=(10, 6))\nplt.plot(losses_vanilla, marker='o', label=\"Vanilla GD (β = 0)\")\nplt.plot(losses_momentum, marker='o', label=\"Momentum GD (β = 0.9)\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Logistic Loss\")\nplt.title(\"Loss over Iterations: Vanilla GD vs. Momentum GD\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see by the plot, gradient descent with momention can converge to the correct weight vector (minimal loss) in fewer iterations than vanilla gradient descent.\n\n\nExperiment 3: Overfitting\nNow we want to test Linear Regression on data with more than two dimensions. The code below generates and trains a logistic regression model on synthetic high-dimensional data using vanilla gradient descent. The generate_high_dim_data function creates a dataset with 50 data points (n_points) and 100 features (p_dim). Each data point has p_dim - 1 features sampled from a standard normal distribution, and a final feature of constant ones is appended as a bias term. Labels (y) are randomly assigned as 0 or 1 with equal probability. Two separate datasets are generated: one for training and one for testing. A logistic regression model is then trained on the training data using a custom GradientDescentOptimizer, which performs 200 iterations of optimization with a learning rate (alpha) of 0.1 and no momentum (beta = 0.0). During training, the loss is recorded at each iteration. Finally, the model’s predictions are evaluated on both the training and test sets, and the corresponding accuracies are printed.\n\ndef generate_high_dim_data(n_points=50, p_dim=100):\n    \"\"\"\n    Generates a dataset with n_points data and p_dim features.\n    The first (p_dim - 1) features are drawn from a standard normal distribution,\n    and the last column is a constant bias (ones).\n    Labels are randomly assigned (0 or 1) with equal probability.\n    \"\"\"\n    # p_dim includes the bias column.\n    X_raw = torch.randn(n_points, p_dim - 1)\n    bias = torch.ones(n_points, 1)\n    X = torch.cat([X_raw, bias], dim=1)\n    y = torch.randint(0, 2, (n_points,)).float()\n    return X, y\n\n# Generate the two datasets independently but with the same parameters.\nX_train, y_train = generate_high_dim_data(n_points=50, p_dim=100)\nX_test, y_test = generate_high_dim_data(n_points=50, p_dim=100)\n\n# === Training the Logistic Regression Model ===\n\nmodel = LogisticRegression()\noptimizer = GradientDescentOptimizer(model)\n\nnum_iterations = 200\ntrain_losses = []\n\nfor i in range(num_iterations):\n    loss = model.loss(X_train, y_train)\n    train_losses.append(loss.item())\n    # Vanilla gradient descent (beta = 0).\n    optimizer.step(X_train, y_train, alpha=0.1, beta=0.0)\n\n# === Evaluate the Model on Training and Test Data ===\n\ntrain_preds = model.predict(X_train)\ntrain_accuracy = (train_preds == y_train).float().mean().item()\n\ntest_preds = model.predict(X_test)\ntest_accuracy = (test_preds == y_test).float().mean().item()\n\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\nprint(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n\nTraining Accuracy: 100.00%\nTest Accuracy: 46.00%\n\n\nAs we can see, while the Logistic Regression classified the data with 100% accuracy on the training set, it only performed with 46% accuracy on the test set. This suggests that the model has overfit the training data—essentially memorizing the patterns in the training set rather than learning generalizable features. Since the dataset is high-dimensional (with 100 features and only 50 data points), the model has enough flexibility to perfectly separate the training points. However, this does not translate to good performance on unseen data, which explains the low accuracy on the test set.\n\n\nExperiment 4: Performance on Empirical Data\nNow we want to test our implementation of Logistic Algorithm on real-world, empirical data. From Kaggle, I found a data set on diabetes on other physical metrics created by GeeksForGeeks. The link to the data set can be found here. The dataset includes key metrics necessary for predictins diabetes such as age, glucose levels, insulin, BMI, etc.\nMy goal is train a Logistic Regression model to predict/classify whether a student passed or failed their final exam based on the academic data.\nI downloaded the data as a .csv file, now I must read it into a data frame.\n\nimport pandas as pd\n\ndf = pd.read_csv('/Users/evanflaks/Downloads/diabetes-dataset.csv')\ndf.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\nNow we prepare our dataset for logistic regression. First, it separates the feature matrix X from the binary target variable y (which indicates whether a person has diabetes). It then standardizes the features using StandardScaler to ensure each has a mean of 0 and standard deviation of 1, which helps the model train more effectively. A column of ones is appended to the feature matrix to act as a bias (intercept) term. Finally, both the feature matrix and target vector are converted into PyTorch tensors to be used in training a logistic regression model.\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n# Split features and target\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Add bias column (intercept term)\nimport numpy as np\nX_scaled = np.hstack([X_scaled, np.ones((X_scaled.shape[0], 1))])\n\n# Convert to torch tensors\nX_tensor = torch.tensor(X_scaled, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.float32)\n\nNow we split our data into training, validation, and testing sets, with a 60%, 20%, and 20% split.\n\n# First: split into 80% train_val and 20% test\nX_temp, X_test, y_temp, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n\n# Then split train_val into 60% train and 20% val =&gt; 0.25 * 0.8 = 0.2\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n\nThis function trains a logistic regression model using gradient descent with optional momentum. It takes the model, optimizer, training and validation data, and hyperparameters like the number of iterations (n_iter), learning rate (alpha), and momentum (beta). Before training begins, it calls model.score(X_train) to ensure the model’s weights are initialized. In each iteration of training, the optimizer updates the model weights, and the function records the loss on both the training and validation sets. After all iterations, it returns two lists containing the training and validation losses over time, which will be used to visualize the model’s learning progress.\n\ndef train(model, optimizer, X_train, y_train, X_val, y_val, n_iter=100, alpha=0.1, beta=0.0):\n    train_losses = []\n    val_losses = []\n\n    # 🔧 Force initialization of model.w before optimizer.step()\n    model.score(X_train)\n\n    for i in range(n_iter):\n        optimizer.step(X_train, y_train, alpha, beta)\n        train_loss = model.loss(X_train, y_train).item()\n        val_loss = model.loss(X_val, y_val).item()\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n    return train_losses, val_losses\n\nThe code below trains two logistic regression models—one using standard gradient descent and the other using gradient descent with momentum—and compares their performance by plotting the training and validation loss over 100 iterations. It first initializes and trains model1 without momentum (\\(\\beta = 0.0\\)), then initializes and trains model2 with momentum (\\(\\beta = 0.9\\)). The recorded loss values for both models are plotted using Matplotlib.\n\nimport matplotlib.pyplot as plt\n\n# Without momentum\nmodel1 = LogisticRegression()\noptimizer1 = GradientDescentOptimizer(model1)\ntrain1, val1 = train(model1, optimizer1, X_train, y_train, X_val, y_val, n_iter=100, alpha=0.1, beta=0.0)\n\n# With momentum\nmodel2 = LogisticRegression()\noptimizer2 = GradientDescentOptimizer(model2)\ntrain2, val2 = train(model2, optimizer2, X_train, y_train, X_val, y_val, n_iter=100, alpha=0.1, beta=0.9)\n\n# Plotting\nplt.plot(train1, label='Train Loss (No Momentum)')\nplt.plot(val1, label='Val Loss (No Momentum)')\nplt.plot(train2, label='Train Loss (With Momentum)')\nplt.plot(val2, label='Val Loss (With Momentum)')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nSimilar to our earlier experiment, in both the validation and training sets, loss monotonically decreases over the course of iterations. For both sets, the decrease is more rapid with Momentum, leveling out earlier. Without momentum, loss decreases more gradually but eventually reaches similar loss levels as the models with momentum.\n\ndef accuracy(model, X, y):\n    preds = model.predict(X)\n    return (preds == y).float().mean().item()\n\nfinal_test_loss = model2.loss(X_test, y_test).item()\nfinal_test_accuracy = accuracy(model2, X_test, y_test)\n\nprint(f\"Test Loss: {final_test_loss:.4f}\")\nprint(f\"Test Accuracy: {final_test_accuracy*100:.2f}%\")\n\nTest Loss: 0.5297\nTest Accuracy: 72.73%\n\n\nOur logistic regression model found a final loss of 0.5297 and an accuracy of 72.73% on the data test set.\n\n\n\nConclusion\nIn this project, I implemented logistic regression from scratch in PyTorch and designed a complete training pipeline with gradient descent, including optional momentum. I began by building three core components: a base LinearModel class for linear predictions, a LogisticRegression class that computes logistic loss and gradients, and a GradientDescentOptimizer that updates weights using gradient descent with momentum. After verifying these implementations, I created synthetic classification data and ran multiple experiments to understand how different optimization settings influence training performance. Specifically, I trained models both with and without momentum, plotted the loss curves over iterations, and visualized the decision boundaries. These visualizations showed that adding momentum accelerated convergence and helped the model better separate the two classes, especially when the data had higher noise. I also tested the model on high-dimensional data, where it achieved perfect accuracy on the training set but performed poorly on unseen test data—highlighting the classic problem of overfitting in high-dimensional spaces with small sample sizes. I then transitioned to a real-world dataset on diabetes and evaluated the model’s predictive performance after preprocessing, scaling, and splitting the data into training, validation, and test sets. The model achieved a much more realistic 72.73% accuracy on the empirical test set, showing that it can generalize better when trained on structured, real-world data. I also analyzed the impact of momentum in gradient descent and found that adding momentum allowed the model to converge more quickly, with smoother and faster decreases in training and validation loss curves. Overall, this project helped me deepen my understanding of loss functions, overfitting, optimization techniques, and the practical challenges of applying machine learning models to real-world data."
  },
  {
    "objectID": "posts/penguins/penguins.html",
    "href": "posts/penguins/penguins.html",
    "title": "Palmer Penguins Classification",
    "section": "",
    "text": "Abstract\nThis goal of this project was to develop a machine learning model to classify penguin species based on quantitative and qualititave characteristics using the Palmer Penguins dataset. After accessing the data and splitting it up into training and testing sets, I created visualizations on the training data to better understand which species exhibited particular traits. Then, I used a feature selection system to determine which features (two quantitative and one qualitiative) would be the best predictor of a penguin’s species. From there, I used these features to train a logistic regression model. The model’s performance is assessed using training and test accuracy and decision region visualizations. The goal of this assignment was to take a penguin with unknown species, analyze three of its given features, and with 100% accuracy, predict its species.\n\n\nData Preparation\nFirst I must access and read the data from the source.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nNow, I must prepare the dataset for machine learning by encoding the target variable (Species) into numerical values, dropping unnecessary columns, removing missing values and invalid entries, converting categorical columns into numerical representations via one-hot encoding, and splitting up training and testing sets.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\n# Initialize LabelEncoder for the target variable\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\n# Function to preprocess data\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]  # Remove rows with invalid 'Sex' values\n    df = df.dropna()  # Remove any remaining missing values\n    y = le.transform(df[\"Species\"])  # Encode the target variable\n    df = df.drop([\"Species\"], axis=1)  # Remove the target column from features\n    df = pd.get_dummies(df)  # One-hot encode categorical features\n    return df, y\n\n# Prepare the dataset\nX, y = prepare_data(train)\n\n# Split the dataset into 80% training and 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Convert training data back into a DataFrame for visualization purposes\ntrain_data = X_train.copy()\ntrain_data[\"Species\"] = le.inverse_transform(y_train)  # Convert encoded labels back to species names\n\n# Reconstruct the 'Island' column from one-hot encoded values\nisland_columns = ['Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\ntrain_data[\"Island\"] = train_data[island_columns].idxmax(axis=1).str.replace(\"Island_\", \"\")\n\n# Check the sizes of the splits\nprint(f\"Training Set Size: {X_train.shape[0]}\")\nprint(f\"Test Set Size: {X_test.shape[0]}\")\n\nTraining Set Size: 204\nTest Set Size: 52\n\n\n\n\nVisualizations\nNow, to visualize the dataset, I have created a scatter plot that plots flipper length vs. body mass of the three species and a bar chart showing the distribution of Penguins found on the three different islands. Finally, I created a summary table that shows each species’ average Culmen Length and Culmen Depth.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=train_data, x='Flipper Length (mm)', y='Body Mass (g)', hue='Species', style='Species')\n\n# Labels and title\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Body Mass (g)')\nplt.title('Flipper Length vs. Body Mass by Species (Training Data Only)')\nplt.legend(title='Species')\nplt.show()\n\n\n\n\n\n\n\n\nAbove, I have created a scatter plot that plots the flipper length and body mass of each penguin observed in the training set. I created a key with different symbols to plot each species so I could visualize the physical differences between each species. This visualization gave me valuable insight, informing me that Gentoo penguins are much larger in terms of body mass and flipper length than both Adelie and Chinstrap penguins. Adelie and Chinstrap penguins, as represented by the blue circles and green squares, share very similar sizes in these metrics. From this, we can conclude that body mass and flipper length would be excellent features with which to train our model in order to distinguish between Gentoo or not-gentoo, but these features would not help our model distinguish between Adelie and Chinstrap.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a count plot for species distribution by island (training data only)\nplt.figure(figsize=(8, 6))\nsns.countplot(data=train_data, x='Island', hue='Species')\n\n# Labels and title\nplt.xlabel('Island')\nplt.ylabel('Count')\nplt.title('Penguin Species Distribution by Island (Training Data Only)')\nplt.legend(title='Species')\nplt.show()\n\n\n\n\n\n\n\n\nFor this visualization, I created a bar chart to see the island where each observed penguin was found. Here, we can see that Gentoo penguins are only found on Biscoe Island and Chinstrap penguins are only found on Dream Island. Adelie penguins, on the other hand, are found on all three islands. This bar chart tells me that Island location could help train my model to distinguish between Adelie and Chinstrap because Chinstrap penguins seem to only be found on Dream Island. So, if we see a penguin with quantitaive measurables that could fall under Adelie or Chinstrap, but the penguin was found on Torgersen Island, the model would correctly predict that the penguin is Adelie. This is especially helpful considering the quantitative features observed in my first visualization had a lot of overlap between Adelie and Chinstrap.\n\nimport pandas as pd\n\n# Compute the average Culmen Length & Depth in the training set only\nsummary_table = train_data.groupby(\"Species\")[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]].mean()\n\n# Display the summary table\nprint(summary_table)\n\n\n                                           Culmen Length (mm)  \\\nSpecies                                                         \nAdelie Penguin (Pygoscelis adeliae)                 39.048837   \nChinstrap penguin (Pygoscelis antarctica)           48.697778   \nGentoo penguin (Pygoscelis papua)                   47.031507   \n\n                                           Culmen Depth (mm)  \nSpecies                                                       \nAdelie Penguin (Pygoscelis adeliae)                18.412791  \nChinstrap penguin (Pygoscelis antarctica)          18.406667  \nGentoo penguin (Pygoscelis papua)                  14.957534  \n\n\nHere, I created a table to see the average culmen length and culmen depth of each penguin species from the data set. From this, we can see that culmen length would be a great feature to distinguish Adelie penguins from the other two species because they have considerably shorter culmens. However, culmen length would not be very helpful in distinguishing Gentoo from Chinstrap because they have very similar measurements. As for culmen depth, we see that Adelie and Chinstrap have very similar average measurements while Gentoo penguins have considerably smaller culmen depths. This means culmen depth would be a good feature for my model to distinguish Gentoo penguins from the other two species.\n\n\nData Visualization Conclusions\nAfter creating three data visualizations, I have intuition for some of the features that would help train a successful model. From my scatter plot, I saw that body mass and flipper length would both be great features to help my model distinguish between Gentoo and Adelie or Chinstrap, but would not be very helpful in distinguishing Adelie from Chinstrap. Then, from the summary table, we could see that Adelie penguins, on average, have around a 20% shorter culmen length than Chinstrap penguins, so that would be a great feature to help my model distinguish between those two species. Finally, since Chinstrap penguins were only found on Dream Island and Gentoo Penguins were only found on Biscoe Island as represented by my bar chart, I figured this would be a nice qualitative feature with which to train my model.\n\n\nFeature Selection\nNow we must choose which three features we want to use to predict the penguin species. I gained some valuable insight from my visualizations but now want to use a systematic approach to select the three best features. To do this, I used a Random Forest Classifier by measuring how much each feature contributes to making accurate predictions. When splitting a node in a decision tree, features that provide better separation between classes are preferred. The model tracks how often a feature is used in important splits and how much it improves classification accuracy. The importance of each feature is calculated as the total reduction in prediction error (impurity) it provides across all trees. Features with higher scores contribute more to the model’s decision-making.\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Train a random forest to assess feature importance\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get feature importance scores\nfeature_importance = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': model.feature_importances_\n})\n\n# Sort by importance\nfeature_importance = feature_importance.sort_values(by='Importance', ascending=False)\nprint(feature_importance)\n\n                     Feature  Importance\n0         Culmen Length (mm)    0.234636\n2        Flipper Length (mm)    0.179364\n5          Delta 13 C (o/oo)    0.161621\n1          Culmen Depth (mm)    0.148071\n4          Delta 15 N (o/oo)    0.075136\n7               Island_Dream    0.063007\n6              Island_Biscoe    0.059049\n3              Body Mass (g)    0.058736\n8           Island_Torgersen    0.012969\n10      Clutch Completion_No    0.002622\n12                Sex_FEMALE    0.002250\n13                  Sex_MALE    0.001822\n11     Clutch Completion_Yes    0.000717\n9   Stage_Adult, 1 Egg Stage    0.000000\n\n\nFrom this, we can conclude that the best qualitative category is Island and the best quantitative categories are Culmen Length and Flipper Length. So, these are the features we will train our model on.\n\n\nLogistic Regression Model Testing\nThe model below uses logistic regression to classify data based on flipper length, culmen length, and island. First, it standardizes the numerical features using StandardScaler() to ensure consistent scaling. Then, it trains a logistic regression model with increased iterations (1000) to ensure convergence. Finally, it evaluates performance using training and test accuracy, helping assess how well the model generalizes.\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\n# Define selected features\ncols = ['Flipper Length (mm)', 'Culmen Length (mm)','Island_Biscoe', 'Island_Dream', 'Island_Torgersen',]\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train[cols]), columns=cols)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test[cols]), columns=cols)\n\n\n# Initialize and train logistic regression with increased iterations\nLR = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\nLR.fit(X_train_scaled, y_train)\n\n# Evaluate model\nprint(\"Training Accuracy:\", LR.score(X_train_scaled, y_train))\nprint(\"Test Accuracy:\", LR.score(X_test_scaled, y_test))\n\n\n\nTraining Accuracy: 0.9754901960784313\nTest Accuracy: 1.0\n\n\n\n\nPlotting Decision Regions\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, scaler):\n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n\n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7, 3))\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n\n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n        XY = pd.DataFrame({X.columns[0]: XX, X.columns[1]: YY})\n\n        # Initialize categorical features as zeros\n        for j in qual_features:\n            XY[j] = 0\n\n        # Set the specific category feature to 1\n        XY[qual_features[i]] = 1\n\n        # Standardize XY to match model input\n        XY_scaled = pd.DataFrame(scaler.transform(XY), columns=X.columns)\n\n        # Predict decision boundary\n        p = model.predict(XY_scaled)\n        p = p.reshape(xx.shape)\n\n        # Use contour plot to visualize the predictions\n        decision_cmap = ListedColormap([\"blue\", \"green\", \"orange\"])  # Match species colors\n        axarr[i].contourf(xx, yy, p, cmap=decision_cmap, alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n\n        # Plot the actual training data points\n        species_cmap = ListedColormap([\"blue\", \"green\", \"orange\"])  # blue = Adelie, Green = Chinstrap, orange = Gentoo\n        axarr[i].scatter(x0[ix], x1[ix], c=y[ix], cmap=species_cmap, vmin=0, vmax=2)\n\n        axarr[i].set(\n            xlabel=X.columns[0],\n            ylabel=X.columns[1],\n            title=qual_features[i]\n        )\n\n        patches = []\n        for color, spec in zip([\"blue\", \"green\", \"orange\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n            patches.append(Patch(color=color, label=spec))\n\n        axarr[i].legend(handles=patches, title=\"Species\", loc=\"best\")\n\n    plt.tight_layout()\n\n# Call the function with scaler applied\nplot_regions(LR, X_train[cols], y_train, scaler)\nplot_regions(LR, X_test[cols], y_test, scaler)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbove, I have plotted my model’s decision regions on both the training and test sets, showing the thresholds of prediction for each species split up by each island.\nFor both the training and test set of penguins on Torgersen Island, my model predicted with 100% success as there were no other penguin found on this island besides Adelies.\nDream Island contained both Adelie and Chinstrap penguins, which both have very similar flipper length, so the decision regions for that island are based almost entirely by culmen length, as can be seen by the near-horizontal divide between the green and blue regions. My model did have some error on the training set for Dream Island as there were some outliers of the decision regions – Chinstraps with below average culmen lengths and Adelies with above average culmen lengths. The test set did not have as many outliers and therefore still predicted with 100% accuracy on Dream Island.\nAs for Biscoe Island, there were both Gentoo and Adelie penguins. As observed in my data visualizations, Gentoo penguins are considerably larger than Adelie in both flipper length and culmen length so the regions are divided diagonally. There were no overlaps in the decision regions on Biscoe in either the test or training set.\nIt is interesting to me that even though no Gentoo or Chinstrap penguins were found on Torgersen in the entire data set, there are still orange and green regions. Similarly, no Gentoos are found on Dream or Torgerson, but my model still has an orange decision region for both of those islands. This makes sense to me because, for instance, if the model found a penguin with a 230 mm flipper length and 60 mm culmen depth on Torgersen, it would be a reasonable prediction for that penguin to be a Gentoo, even if there are no other Gentoos on the island.\n\n\nConfusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test_scaled)\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[22,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 19]])\n\n\nAbove is my models confusion matrix for the test set. The rows represent the actual species of a penguin while the columns represent the predicted species. As we can see, my model predicted all 22 Adelies to be Adelie, all 11 Chinstraps to be Chinstraps, and all 19 Gentoos to be gentoos. Therefore, my model correctly predicted the species of all 52 penguins in the test set with no errors.\n\n\nDiscussion\nThroughout this project, I gained valuable insights into the entire machine learning process. First, it was essential to prepare the data into training and test sections, encode qualitative regions into quantitave values, drop unessecary columns, and simplify column names. Then, the data visualizations helped me uncover trends in the dataset. This allowed me to get a foundational understanding of the variance between the species’ characteristics. A key takeaway was the importance of feature selection. I initially just analyzed my data visualizations and chose features I thought would be strong predictors. Even though this was somewhat accurate, when I automated my feature selection with a RandomForestClassifier and chose the most statistically important feautures, I was able to bring my model’s prediction success up to 100% for the test set. I also gained experience with model selection and scaling. After trying out a few options, I chose the Logistic Regression model because it was consistently high performing. During this process, I also realized that I had to standardize the numerical features to ensure consistent scaling. Perhaps the most interesting discovery of the entire process was plotting the decision regions to see where my model numerically distinguished between the species’ and to see the entire regions where a particular species would fall."
  },
  {
    "objectID": "posts/bias/bias.html",
    "href": "posts/bias/bias.html",
    "title": "Auditing Bias",
    "section": "",
    "text": "Abstract\nThis project investigates the use of machine learning to predict employment status based on demographic and socioeconomic variables from the U.S. Census PUMS data. Using the folktables library, we sourced data from the state of Maryland and preprocessed it to extract relevant features. A Random Forest model was trained to classify employment status, and its performance was evaluated on the general Maryland population. Then, a bias audit was conducted to assess potential disparities in model predictions across different racial and demographic groups. The results highlight both the predictive capabilities of the model and the ethical concerns related to bias in employment predictions.\n\n\nDownloading Data\nFirst we will download some PUMS data from the state of Maryland using folktables.\n\nfrom folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\nimport numpy as np\n\nSTATE = \"MD\"\n\ndata_source = ACSDataSource(survey_year='2023', \n                            horizon='1-Year', \n                            survey='person')\n\nacs_data = data_source.get_data(states=[STATE], download=True)\n\nacs_data.head()\n\n\n\n\n\n\n\n\nRT\nSERIALNO\nDIVISION\nSPORDER\nPUMA\nREGION\nSTATE\nADJINC\nPWGTP\nAGEP\n...\nPWGTP71\nPWGTP72\nPWGTP73\nPWGTP74\nPWGTP75\nPWGTP76\nPWGTP77\nPWGTP78\nPWGTP79\nPWGTP80\n\n\n\n\n0\nP\n2023GQ0000068\n5\n1\n201\n3\n24\n1019518\n27\n62\n...\n27\n29\n24\n25\n29\n27\n25\n29\n28\n28\n\n\n1\nP\n2023GQ0000079\n5\n1\n502\n3\n24\n1019518\n13\n21\n...\n13\n26\n17\n15\n13\n32\n0\n2\n2\n13\n\n\n2\nP\n2023GQ0000088\n5\n1\n1400\n3\n24\n1019518\n25\n35\n...\n32\n25\n70\n54\n42\n24\n2\n34\n49\n23\n\n\n3\nP\n2023GQ0000093\n5\n1\n1300\n3\n24\n1019518\n19\n61\n...\n14\n19\n23\n27\n2\n22\n27\n3\n20\n2\n\n\n4\nP\n2023GQ0000100\n5\n1\n802\n3\n24\n1019518\n106\n73\n...\n136\n206\n9\n15\n106\n209\n115\n210\n211\n15\n\n\n\n\n5 rows × 287 columns\n\n\n\n\n\nData Cleaning\nThe dataset has a lot of features. For our modeling task, we will only use the following possible features\n\npossible_features=['AGEP', 'SCHL', 'MAR', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']\nacs_data[possible_features].head()\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\nRAC1P\nESR\n\n\n\n\n0\n62\n17.0\n5\n1\nNaN\n1\n1.0\n4.0\n4\n1\n2\n1\n1.0\n1\n1\n6.0\n\n\n1\n21\n19.0\n5\n2\nNaN\n1\n1.0\n4.0\n2\n1\n2\n2\n2.0\n2\n9\n6.0\n\n\n2\n35\n16.0\n5\n2\nNaN\n1\n1.0\n4.0\n1\n1\n2\n2\n2.0\n1\n2\n6.0\n\n\n3\n61\n18.0\n3\n1\nNaN\n1\n3.0\n4.0\n4\n1\n2\n2\n1.0\n1\n1\n6.0\n\n\n4\n73\n13.0\n5\n1\nNaN\n1\n1.0\n4.0\n4\n1\n2\n2\n2.0\n1\n1\n6.0\n\n\n\n\n\n\n\nFor documentation on what these features mean, please consult the appendix of this paper that introduced the package.\nI am going to train my model on all of the possible features aside from race, because we will be auditing for racial bias later. I will use these features to predict employment status (ESR), so that column of data will also be discluded from my training.\n\nfeatures_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]\n\nNow we can construct a BasicProblem that expresses our wish to use these feautures to predict employment status (ESR), using race (RAC1P) as the group label.\n\nEmploymentProblem = BasicProblem(\n    features=features_to_use,\n    target='ESR',\n    target_transform=lambda x: x == 1,\n    group='RAC1P',\n    preprocess=lambda x: x,\n    postprocess=lambda x: np.nan_to_num(x, -1),\n)\n\nfeatures, label, group = EmploymentProblem.df_to_numpy(acs_data)\n\nBefore we touch the data anymore, we should perform a train-test split, training our model on 80% of the data, and testing on the remaining 20%.\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n    features, label, group, test_size=0.2, random_state=0)\n\n\n\nData Exploration\nNow we want to answer some basic questions about the data we are working with. We can answer these questions by turning our training data into a data frame for easy analysis.\n\nimport pandas as pd\ndf = pd.DataFrame(X_train, columns = features_to_use)\ndf[\"group\"] = group_train\ndf[\"label\"] = y_train\ndf.head()\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\ngroup\nlabel\n\n\n\n\n0\n4.0\n1.0\n5.0\n2.0\n5.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n0.0\n1.0\n1\nFalse\n\n\n1\n2.0\n0.0\n5.0\n2.0\n1.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n0.0\n1.0\n1\nFalse\n\n\n2\n49.0\n21.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n2.0\n1.0\n2.0\n2.0\n2.0\n1.0\n1\nFalse\n\n\n3\n47.0\n15.0\n5.0\n1.0\n0.0\n3.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n1.0\n2.0\n1\nTrue\n\n\n4\n0.0\n0.0\n5.0\n2.0\n1.0\n1.0\n0.0\n0.0\n1.0\n1.0\n2.0\n2.0\n0.0\n1.0\n1\nFalse\n\n\n\n\n\n\n\n\n1. How many individuals are in the data?\n\ndf.shape[0]\n\n49624\n\n\n\n\n2. Of these individuals, what proportion are employed?\n\ndf[\"label\"].mean()\n\n0.4898839271320329\n\n\n\n\n3. Of these individuals, how many are in each racial group?\n\n# Count the number of employed people in each racial group\ndf[df[\"label\"] == 1].groupby(\"group\")[\"label\"].count()\n\ngroup\n1    14026\n2     5131\n3       93\n4        1\n5       19\n6     2046\n7       12\n8     1247\n9     1735\nName: label, dtype: int64\n\n\nThe race groups are broken down as follows: – 1: White alone  – 2: Black or African American alone  – 3: American Indian alone – 4: Alaska Native alone – 5: American Indian and Alaska Native – 6: Asian alone – 7: Native Hawaiian and Other Pacific Islander alone – 8: Some Other Race alone – 9: Two or More Races\n\n\n4. In each group, what proportion of individuals have target label equal to 1, i.e. what proportion of people in each race is employed?\n\n# Compute the proportion of employed individuals in each racial group\ndf.groupby(\"group\")[\"label\"].mean()\n\ngroup\n1    0.491761\n2    0.478415\n3    0.547059\n4    0.333333\n5    0.372549\n6    0.544874\n7    0.666667\n8    0.513169\n9    0.439241\nName: label, dtype: float64\n\n\n\n\nNow I will look for some intersectional trends.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Create a DataFrame with the training features\ndf = pd.DataFrame(X_train, columns=features_to_use)\n\n# Add the race and employment status columns separately\ndf[\"Race\"] = group_train  # This is the group label provided separately\ndf[\"Employment Status\"] = y_train  # 1 = Employed, 0 = Not employed\n\n# Extract Sex feature\ndf[\"Sex\"] = X_train[:, features_to_use.index(\"SEX\")]\n# Replace numeric values with \"Male\" and \"Female\"\ndf[\"Sex\"] = df[\"Sex\"].replace({1: \"Male\", 2: \"Female\"})\n\n# Rename race labels dynamically\nunique_races = df[\"Race\"].unique()\nrace_labels = {race: f\"Race {race}\" for race in unique_races}\ndf[\"Race\"] = df[\"Race\"].replace(race_labels)\n\n# Compute the proportion of employed individuals by race and sex\nintersectional_proportions = df.groupby([\"Race\", \"Sex\"])[\"Employment Status\"].mean().reset_index()\n\n# Plot the results\nplt.figure(figsize=(10, 6))\nax = sns.barplot(data=intersectional_proportions, x=\"Race\", y=\"Employment Status\", hue=\"Sex\")\n\n# Add numerical labels on top of each bar\nfor p in ax.patches:\n    if p.get_height() &gt; 0:  # Only annotate bars with nonzero height\n        ax.annotate(f'{p.get_height():.2f}',  # Format proportion to 2 decimal places\n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha='center', va='bottom', fontsize=10, color='black')\n\n# Adjust plot aesthetics\nplt.title(\"Proportion of Employed Individuals by Sex and Race\")\nplt.ylabel(\"Proportion Employed\")\nplt.xlabel(\"Race\")\nplt.xticks(rotation=45)  # Rotate labels for better visibility\nplt.legend(title=\"Sex\")\nplt.ylim(0, 1)\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nThis visualization gives us some valuable insights. The main outliers are only 30% of female Alaskan Natives (race 5) are employed and around 83% of male Pacific Islanders (race 7) are employed. Another thing to note is there are 0 employed male Alaskan natives (race 4), and this is because the training data set only includes one employed Alaskan native, and that person is female. Aside from those outliers, members from all racial groups have similar proportion of employed individuals (0.42-0.59), with males being employed at higher rates than women for every racial group besides Black people (race 2).\n\n\n\nTraining a Model\nThis Random Forest model undergoes hyperparameter tuning using GridSearchCV, where different values for max_depth (the maximum depth of each tree) are tested through 5-fold cross-validation to determine the best-performing configuration based on accuracy. Once the optimal max_depth is found, the best model is evaluated using cross-validation to estimate its generalization performance. Finally, the model is retrained on the full training dataset to maximize learning before deployment.\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n\n# Define the Random Forest Classifier\nrf = RandomForestClassifier(n_estimators=100, random_state=0)\n\n# Define hyperparameters to tune\nparam_grid_rf = {'max_depth': [3, 5, 10, None]}  # Tune max depth\n\n# Perform Grid Search with Cross-Validation\ngrid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\ngrid_rf.fit(X_train, y_train)\n\n# Get the best model from Grid Search\nbest_rf_model = grid_rf.best_estimator_\n\n# Print the best max_depth value\nprint(\"Best max_depth for Random Forest:\", grid_rf.best_params_['max_depth'])\n\n# Evaluate the model with cross-validation\nrf_score = cross_val_score(best_rf_model, X_train, y_train, cv=5).mean()\nprint(f\"Cross-validation accuracy: {rf_score:.4f}\")\n\n# Train the final model on the full training set\nbest_rf_model.fit(X_train, y_train)\n\nBest max_depth for Random Forest: 10\nCross-validation accuracy: 0.8287\n\n\nRandomForestClassifier(max_depth=10, random_state=0)\n\n\nBased on our cross-validation results, the optimal accuracy of our model is achieved with a max_depth of 10.\nWith a max_depth of 10, our Random Forest model predicted employment with an accuracy of approximately 82% on the training data.\n\n\nTesting My Model\n\nOverall Accuracy and Precision\nFirst let’s see the overall accuracy of our model on the entire test set, without considering different racial groups.\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix\n\n# Make predictions on the test set\ny_pred = best_rf_model.predict(X_test)\ndef compute_metrics(y_true, y_pred):\n    C = confusion_matrix(y_true, y_pred)\n\n    # Extract confusion matrix values manually\n    tn = C[0, 0] \n    fp = C[0, 1] \n    fn = C[1, 0] \n    tp = C[1, 1] \n\n    # Compute metrics\n    accuracy = (y_pred == y_true).mean()\n    ppv = tp / (tp + fp) \n    fnr = fn / (fn + tp) \n    fpr = fp / (fp + tn)\n\n    return pd.Series({\"Accuracy\": accuracy, \"PPV\": ppv, \"FNR\": fnr, \"FPR\": fpr})\n\n\ncompute_metrics(y_test, y_pred)\n\nAccuracy    0.826388\nPPV         0.792269\nFNR         0.121975\nFPR         0.223812\ndtype: float64\n\n\n\n\nTesting By Racial Group\nNow let’s check out some of the metrics split up by racial group.\n\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\n\n# Create DataFrame with predictions and actual values\ndf_results = pd.DataFrame({\"true_employment\": y_test, \"predicted_employment\": y_pred, \"race\": group_test})\n\n# Apply function to each subgroup\nresults_df = df_results.groupby(\"race\").apply(lambda g: compute_metrics(g[\"true_employment\"], g[\"predicted_employment\"]))\nresults_df\n\n\n\n\n\n\n\n\nAccuracy\nPPV\nFNR\nFPR\n\n\nrace\n\n\n\n\n\n\n\n\n1\n0.827839\n0.801902\n0.134550\n0.208914\n\n\n2\n0.814081\n0.770961\n0.131336\n0.235789\n\n\n3\n0.822222\n0.777778\n0.086957\n0.272727\n\n\n5\n0.850000\n0.700000\n0.000000\n0.230769\n\n\n6\n0.806999\n0.768116\n0.073786\n0.336449\n\n\n7\n0.818182\n0.750000\n0.250000\n0.142857\n\n\n8\n0.838879\n0.808260\n0.089701\n0.240741\n\n\n9\n0.860887\n0.803435\n0.076754\n0.192164\n\n\n\n\n\n\n\n\n\n\nAuditing For Racial Bias\nNow let’s analyze our data through the lens of various bias measures to see how it impacts different racial groups differently. To measure these biases, I will refer to the above results_df data frame that includes the model’s metrics divied up by racial group.\n\nCalibration\nNow I will preforming a check to see if my model is calibrated with respect to racial group. the code below calculates the actual true employment rate for each group, but only for cases where the model predicted employment. When I group by race and take the mean of Predicted Employment, it measures how often a positive prediction was actually correct within each racial group. This helps determine if the model’s positive predictions are equally reliable across racial groups.\n\nimport numpy as np\n\n# Compute actual employment rate when model predicts 1, by racial group\ncalibration_check = df_results[df_results[\"predicted_employment\"] == 1].groupby(\"race\")[\"true_employment\"].mean()\ncalibration_check\n\nrace\n1    0.801902\n2    0.770961\n3    0.777778\n5    0.700000\n6    0.768116\n7    0.750000\n8    0.808260\n9    0.803435\nName: true_employment, dtype: float64\n\n\nWhile the model seems to be generally well calibrated, there is an outlier for racial group 5 (Alaska Native), which has 0.05 lower calibration than the next lowest group. This is most likely due to this group having much less data than the other groups, as there were only 19 employed Alaskan natives in the data set. Aside from this group, the model is generally well calibrated as actual employment rates for individuals predicted as employed is fairly consistent, ranging from 0.75 to 0.80. While it is not perfectly calibrated because the values have variance, the level of consistency and a small range indicates that there is no severe calibration bias.\n\n\nError Rate Balance\nError rate balance requires that FPR and FNR be approximately equal across all groups. In my model, there is significant variation in both FNR and FPR across groups. FPR ranges from 0.143 to to 0.336 and FNR ranges between 0.000 and 0.25. This means that some groups are disproportionately classified as false positives or false negatives, and our model does not have balanced error-rates.\n\n\nStatistical Parity\nNow I will check for statistical parity, which is a fairness metric to determine whether different demographic groups receive favorable outcomes at the same rate. The code below checks the proportion of individuals predicted as employed (favorable outcome) within each group by grouping the dataset by Race and computing the mean of the predicted values. This tells us whether the model’s predictions are distributed equally across different groups.\n\n# Compute the proportion of individuals predicted as employed (y_hat == 1) per group\nstatistical_parity_check = df_results.groupby(\"Race\")[\"Predicted Employment\"].mean()\nstatistical_parity_check\n\nRace\n1    0.533390\n2    0.537954\n3    0.600000\n5    0.500000\n6    0.658537\n7    0.363636\n8    0.593695\n9    0.528226\nName: Predicted Employment, dtype: float64\n\n\nA model satisfies statistical parity if each racial group receives the positive prediction at the same rate. Looking at our values from above, the predicted employment rates range from 0.363 (group 7) to 0.658 (group 6), with significant variation among all racial groups. Thus, my model does not achieve statistical parity.\n\n\n\nFeasible FNR and FPR Rates\nAlexandra Chouldechova’s work on fair predictions provides us with the equation \\[\n  FPR = \\frac{1}{1-p}\\frac{1-PPV}{PPV}(1-FNR)\n\\]\nNow I will calculate feasible false positive rates for each group using the above equation by factoring in the prevelance (p). The code computes the prevalence for each group by averaging the true employment rates and then merges this dataframe with our previous results from above. Then, using the equation from above, it calculates a feasible FPR for each group.\n\nimport pandas as pd\n\n# Assuming results_df already contains 'group', 'PPV', 'FNR', and 'FPR'\n# Compute prevalence (p) for each group using y_test from df_results (individual-level data)\nprevalence = df_results.groupby(\"race\")[\"true_employment\"].mean().reset_index()\nprevalence.columns = [\"race\", \"Prevalence\"]\n\n# Merge prevalence into results_df\nresults_df = results_df.merge(prevalence, on=\"race\", how=\"left\")\n\n# Compute Feasible FPR using Equation (2.6)\nresults_df[\"Feasible_FPR\"] = (results_df[\"Prevalence\"] / (1 - results_df[\"Prevalence\"])) * \\\n                             ((1 - results_df[\"PPV\"]) / results_df[\"PPV\"]) * \\\n                             (1 - results_df[\"FNR\"])\n\nresults_df\n\n\n\n\n\n\n\n\nrace\nAccuracy\nPPV\nFNR\nFPR\nPrevalence\nFeasible_FPR\n\n\n\n\n0\n1\n0.827839\n0.801902\n0.134550\n0.208914\n0.494224\n0.208914\n\n\n1\n2\n0.814081\n0.770961\n0.131336\n0.235789\n0.477448\n0.235789\n\n\n2\n3\n0.822222\n0.777778\n0.086957\n0.272727\n0.511111\n0.272727\n\n\n3\n5\n0.850000\n0.700000\n0.000000\n0.230769\n0.350000\n0.230769\n\n\n4\n6\n0.806999\n0.768116\n0.073786\n0.336449\n0.546129\n0.336449\n\n\n5\n7\n0.818182\n0.750000\n0.250000\n0.142857\n0.363636\n0.142857\n\n\n6\n8\n0.838879\n0.808260\n0.089701\n0.240741\n0.527145\n0.240741\n\n\n7\n9\n0.860887\n0.803435\n0.076754\n0.192164\n0.459677\n0.192164\n\n\n\n\n\n\n\nNow I will recreate Chouldechova’s figure 5 from the reading by plotting the observed false negative rates (FNR) and false positive rates (FPR) for each group with the theoretically feasible FNR-FPR tradeoff lines derived from Equation 2.6. The tradeoff lines are calculated using the prevalence-adjusted feasible FPR values, showing the relationship between error rates across groups.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Extract observed values from results_df\ngroups = results_df[\"race\"]\nFNR = results_df[\"FNR\"]\nFPR = results_df[\"FPR\"]\nFeasible_FPR = results_df[\"Feasible_FPR\"]  # Precomputed from the equation\n\n# Define colors for each group\ncolors = plt.cm.tab10(np.linspace(0, 1, len(groups)))  # Using tab10 colormap\n\n# Generate feasible FNR-FPR tradeoff line using equation\nfnr_range = np.linspace(0, 1, 100)\n\n# Compute target FPR (equalizing across all groups)\ntarget_fpr = np.mean(FPR)\n\n# Define prevalence (p) and positive predictive value (PPV) - Assumed fixed\np = 0.5  # Example prevalence\nppv = 0.6  # Example PPV\n\n# Compute required FNR adjustments using Equation (2.6)\nRequired_FNR_Adjustment = 1 - (target_fpr * (1 - p) * ppv) / (p * (1 - ppv)) - FNR\n\n# Store adjustments back into results_df\nresults_df[\"Required_FNR_Adjustment\"] = Required_FNR_Adjustment\n\n# Create figure\nplt.figure(figsize=(7, 5))\n\n# Plot feasible tradeoff lines and corresponding observed points\nfor i, group in enumerate(groups):\n    color = colors[i]  # Assign color to group\n    plt.plot(fnr_range, Feasible_FPR[i] * (1 - fnr_range), color=color, label=f\"Feasible for Group {group}\")\n    plt.scatter(FNR[i], FPR[i], color=color, edgecolors=\"black\", s=50, zorder=3)  # Matching color with a black outline\n\n# Labels and styling\nplt.xlabel(\"False Negative Rate (FNR)\")\nplt.ylabel(\"False Positive Rate (FPR)\")\nplt.title(\"Feasible (FNR, FPR) Combinations with Prevalence Constraint\")\nplt.legend()\nplt.grid(True, linestyle=\"--\", alpha=0.6)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nresults_df[\"Required_FNR_Adjustment\"]\n\n0    0.516623\n1    0.519837\n2    0.564217\n3    0.651173\n4    0.577387\n5    0.401173\n6    0.561472\n7    0.574419\nName: Required_FNR_Adjustment, dtype: float64\n\n\nBy analyzing the relationship between false negative rates (FNR) and false positive rates (FPR) through the lens of equation (2.6), we gain a clearer picture of how the model’s predictive fairness varies across different groups. The plot juxtaposes actual FNR-FPR values with theoretically feasible ones under fixed prevalence and positive predictive value (PPV), revealing where disparities exist. While some groups align closely with the expected trade-offs, others display noticeable deviations, indicating imbalances in error distribution. Achieving fairness by equalizing FPR across all groups requires altering FNR values, as indicated by the Required_FNR_Adjustment metric. The degree of necessary modification varies, with certain groups needing only minor shifts while others require substantial recalibration. For instance, Group 3 exhibits the most significant adjustment, suggesting that its current FNR is considerably lower than what would be necessary for parity. Conversely, Group 5 requires minimal changes, implying it is already near the target threshold. These discrepancies highlight the challenge of enforcing fairness constraints while preserving model accuracy.\n\n\nConcluding Discussion\nThe ability to predict employment status based on demographic features presents significant opportunities for companies and government agencies seeking to improve hiring decisions, workforce planning, and policy implementation. Businesses in recruitment, human resources, and economic forecasting could leverage such a model to streamline hiring processes or assess labor market trends. However, the deployment of such a system requires careful consideration of ethical and fairness concerns.\nThe bias audit conducted in this project revealed disparities in the model’s predictions across racial groups, suggesting that certain demographic segments might be disproportionately misclassified. This raises concerns about the potential reinforcement of existing societal inequalities if the model is applied at scale without proper fairness interventions. In this model there were calibration disparities, higher error rates for certain groups, and a lack of statistical parity across groups.\nBeyond bias, additional concerns arise when deploying predictive models in high-stakes scenarios. The risk of automation bias, where decision-makers over-rely on model predictions without critical assessment, can exacerbate discriminatory outcomes. Additionally, the model’s reliance on historical data means that it may inherit and perpetuate past biases embedded in employment practices.\nTo address these challenges, future improvements should include fairness-aware training techniques, such as reweighting methods, or post-processing corrections. Moreover, continuous monitoring and auditing should be implemented to assess model performance across demographic groups regularly. Transparent reporting and explainability techniques should also be adopted to ensure that stakeholders understand the basis of predictions and can intervene where necessary.\nUltimately, while machine learning models offer powerful tools for employment status prediction, their real-world application must be guided by ethical considerations and fairness audits, to prevent harmful unintended consequences."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Evan Flaks’ Machine Learning Blog",
    "section": "",
    "text": "Sparse Kernelized Logistic Regression\n\n\n\n\n\nImplementing Kernelized Logistic Regression and Performing Various Data Experiments\n\n\n\n\n\nApr 16, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Logistic Regression\n\n\n\n\n\nImplementing Logistic Regression and Performing Various Data Experiments\n\n\n\n\n\nApr 8, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing the Perceptron Algorithm\n\n\n\n\n\nImplementating the perceptron algorithm and testing it in several experiments.\n\n\n\n\n\nMar 23, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\n\n\n\n\n\n\nAuditing Bias\n\n\n\n\n\nBuilding a model that predicts employment status and auditing the model’s racial bias\n\n\n\n\n\nMar 9, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\n\n\n\n\n\n\nDesign and Impact of Automated Decision Systems\n\n\n\n\n\nBuilding and analyzing an automated system for a bank extending credit\n\n\n\n\n\nMar 5, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins Classification\n\n\n\n\n\nMachine Learning model to predict penguin species\n\n\n\n\n\nFeb 18, 2025\n\n\nEvan Flaks\n\n\n\n\n\n\nNo matching items"
  }
]